{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanatory factor analysis\n",
    "\n",
    "Factor analysis is a statistical method used to describe variability among observed, correlated variables in terms of a potentially lower number of unobserved variables called factors. For example, it is possible that variations in six observed variables mainly reflect the variations in two unobserved (underlying) variables. Factor analysis searches for such joint variations in response to unobserved latent variables. The observed variables are modelled as linear combinations of the potential factors, plus \"error\" terms. The information gained about the interdependencies between observed variables can be used later to reduce the set of variables in a dataset.\n",
    "\n",
    "The main idea of factor analysis is to reduce the dimensionality of the data by representing the observed variables in terms of a few underlying factors. The factor model is given by:\n",
    "\n",
    "$$X = LF + \\epsilon$$\n",
    "\n",
    "where:  \n",
    "$X$ is the $n \\times p$ data matrix, where $n$ is the number of observations and $p$ is the number of variables.\n",
    "$L$ is the $n \\times k$ matrix of factor loadings, where $k$ is the number of factors.\n",
    "$F$ is the $k \\times p$ matrix of factors.\n",
    "$\\epsilon$ is the $n \\times p$ matrix of errors.\n",
    "\n",
    "The factor loadings matrix $L$ represents the correlation between the variables and the factors. The factors are uncorrelated with each other and have unit variance. The errors $\\epsilon$ are uncorrelated with each other and with the factors. The factor analysis model can be estimated using the principal component analysis (PCA) method. The PCA method is based on the eigenvalue decomposition of the covariance matrix of the data matrix $X$. The factor loadings matrix $L$ is given by the eigenvectors of the covariance matrix, and the factors matrix $F$ is given by the principal components of the data matrix $X$. The number of factors $k$ is determined by the number of eigenvalues greater than one. The factor analysis model can be estimated using the `FactorAnalysis` class from the `sklearn.decomposition` module. The `FactorAnalysis` class uses the maximum likelihood method to estimate the factor loadings matrix $L$ and the factors matrix $F$. The `FactorAnalysis` class has the following parameters: \n",
    "- `n_components`: the number of factors.\n",
    "- `rotation`: the rotation method to use. The possible values are 'varimax', 'quartimax', 'promax', and 'orthomax'.\n",
    "- `tol`: the tolerance for the convergence of the EM algorithm.\n",
    "- `max_iter`: the maximum number of iterations for the EM algorithm.\n",
    "\n",
    "### Factor analysis assumptions\n",
    "Factor analysis makes the following assumptions:\n",
    "- The observed variables are linear combinations of the factors and the errors.\n",
    "- The factors are uncorrelated with each other.\n",
    "- The errors are uncorrelated with each other and with the factors.\n",
    "- The errors are normally distributed with zero mean and constant variance.\n",
    "\n",
    "### Factor loading\n",
    "The outputs of factor analysis are called \"factor loadings\". The factor loadings represent the correlation between the variables and the factors. The factor loadings can be interpreted as the weights of the variables in the linear combination that represents the factors. The factor loadings can be used to identify the underlying structure of the data and to reduce the dimensionality of the data.\n",
    "\n",
    "Loadings close to 1 or -1 indicate that the variable is strongly correlated with the factor. Loadings close to 0 indicate that the variable is not correlated with the factor. Loadings close to 0.5 or -0.5 indicate that the variable is moderately correlated with the factor.  \n",
    "\n",
    "\n",
    "In this notebook, we will use the `FactorAnalysis` class to estimate the factor loadings matrix and the factors matrix of the data matrix $X$. We will use the `FactorAnalysis` class to estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor analysis on iris dataset\n",
    "\n",
    "We're going to be using the built-in iris dataset from scikit-learn, so that's all set up for you. Our variable X is going to be iris data, and then we also have the variable names which we take from the built-in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris =  datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "variable_names = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.706989         -0.158005           1.654236           0.70085\n",
      "1           0.115161          0.159635          -0.044321          -0.01403\n",
      "2          -0.000000          0.000000           0.000000           0.00000\n",
      "3          -0.000000          0.000000           0.000000          -0.00000\n"
     ]
    }
   ],
   "source": [
    "factor = FactorAnalysis().fit(X)\n",
    "\n",
    "df = pd.DataFrame(factor.components_, columns=variable_names)\n",
    "print(df) \n",
    "# Factor Loadings Matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the factor loadings\n",
    "The factor loadings represent the correlations between the observed variables (sepal length, sepal width, petal length, and petal width) and the factors extracted in a factor analysis. Hereâ€™s an interpretation of the provided loadings:\n",
    "### Interpretation:\n",
    "1. **Factor 0**:\n",
    "\n",
    "- **High Loadings on Petal Length (1.654236) and Petal Width (0.70085)**: This indicates that Factor 0 is strongly associated with petal dimensions. Petal length and width have high positive loadings, suggesting that this factor primarily represents the petal-related features of the iris flowers. The positive loading on petal length and petal width means that as these measurements increase, the value of Factor 0 also increases.\n",
    "- **Moderate Loading on Sepal Length (0.706989)**: Factor 0 also has a moderate positive loading on sepal length, which might suggest some association with the overall size of the flower.\n",
    "- **Low Loading on Sepal Width (-0.158005)**: The negative loading here is weak, indicating that sepal width does not contribute significantly to Factor 0.\n",
    "2. **Factor 1**:\n",
    "\n",
    "- **Low Positive Loadings Across All Variables**: Factor 1 has small loadings on all variables, indicating it does not strongly relate to any particular measurement of the iris flowers. The loadings are close to zero, suggesting that Factor 1 might be capturing some noise or less meaningful variance in the data.\n",
    "3. **Factor 2 and Factor 3**:\n",
    "\n",
    "- **All Loadings are Zero or Near Zero**: Both Factor 2 and Factor 3 have all loadings at zero or very close to zero for all variables. This suggests that these factors do not capture any substantial variance in the observed measurements of the iris flowers. They might not be contributing meaningful information to the factor analysis in this context.\n",
    "\n",
    "### Summary:\n",
    "- Factor 0 seems to be a significant factor that captures the variance related to petal dimensions, and to a lesser extent, sepal length.\n",
    "- Factor 1 does not strongly correlate with any of the features, suggesting it might be less informative or capturing less relevant variance.\n",
    "- Factors 2 and 3 do not contribute any meaningful information based on the given loadings.\n",
    "\n",
    "In practical terms, you might focus on Factor 0 as it appears to provide the most significant insights into the petal characteristics of the iris flowers. Factors 1, 2, and 3 could be considered less relevant for your analysis or model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
